{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nBrain co-registration from MP2RAGE data\n========================================\n\nThis example shows how to co-register MP2RAGE data\nby performing the following steps:\n\n1. Downloading two open MP2RAGE datasets using\n    :func:`nighres.data.download_7T_TRT`\n2. Remove the skull and create a brain mask using\n    :func:`nighres.brain.mp2rage_skullstripping`\n3. Co-register non-linearly the brains using\n    :func:`nighres.registration.embedded_antsreg` [1]_\n4. Deform additional contrasts using\n    :func:`nighres.registration.apply_deformation`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import and download\n-------------------\nFirst we import ``nighres`` and the ``os`` module to set the output directory\nMake sure to run this file in a  directory you have write access to, or\nchange the ``out_dir`` variable below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nighres\nimport os\n\nin_dir = os.path.join(os.getcwd(), 'nighres_examples/data_sets')\nout_dir = os.path.join(os.getcwd(), 'nighres_examples/brain_registration')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also try to import Nilearn plotting functions. If Nilearn is not\ninstalled, plotting will be skipped.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skip_plots = False\ntry:\n    from nilearn import plotting\nexcept ImportError:\n    skip_plots = True\n    print('Nilearn could not be imported, plotting will be skipped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we download an example MP2RAGE dataset. It is the structural scan of the\nfirst subject, first session of the 7T Test-Retest dataset published by\nGorgolewski et al (2015) [2]_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset1 = nighres.data.download_7T_TRT(in_dir, subject_id='sub001_sess1')\ndataset2 = nighres.data.download_7T_TRT(in_dir, subject_id='sub002_sess1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Skull stripping\n----------------\nFirst we perform skull stripping. Only the second inversion image is required\nto calculate the brain mask. But if we input the T1map and T1w image as well,\nthey will be masked for us. We also save the outputs in the ``out_dir``\nspecified above and use a subject ID as the base file_name.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skullstripping_results1 = nighres.brain.mp2rage_skullstripping(\n                                            second_inversion=dataset1['inv2'],\n                                            t1_weighted=dataset1['t1w'],\n                                            t1_map=dataset1['t1map'],\n                                            save_data=True,\n                                            file_name='sub001_sess1',\n                                            output_dir=out_dir, overwrite=False)\n\nskullstripping_results2 = nighres.brain.mp2rage_skullstripping(\n                                            second_inversion=dataset2['inv2'],\n                                            t1_weighted=dataset2['t1w'],\n                                            t1_map=dataset2['t1map'],\n                                            save_data=True,\n                                            file_name='sub002_sess1',\n                                            output_dir=out_dir, overwrite=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip:: in Nighres functions that have several outputs return a\n   dictionary storing the different outputs. You can find the keys in the\n   docstring by typing ``nighres.brain.mp2rage_skullstripping?`` or list\n   them with ``skullstripping_results.keys()``\n\nTo check if the skull stripping worked well we plot the brain mask on top of\nthe original image. You can also open the images stored in ``out_dir`` in\nyour favourite interactive viewer and scroll through the volume.\n\nLike Nilearn, we use Nibabel SpatialImage objects to pass data internally.\nTherefore, we can directly plot the outputs using `Nilearn plotting functions\n<http://nilearn.github.io/plotting/index.html#different-plotting-functions>`_\n.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_roi(skullstripping_results1['brain_mask'], dataset1['t1map'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')\n    plotting.plot_roi(skullstripping_results2['brain_mask'], dataset2['t1w'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SyN co-registration\n ---------------------\n Next, we use the masked data as input for co-registration. The T1 maps are\n used here as they are supposed to be more similar\nsyn_results = nighres.registration.embedded_syn(\n                        source_image=skullstripping_results1['t1map_masked'],\n                        target_image=skullstripping_results2['t1map_masked'],\n                        coarse_iterations=0,\n                        medium_iterations=0, fine_iterations=0,\n                        run_rigid_first=True, cost_function='MutualInformation',\n                        interpolation='NearestNeighbor',\n                        save_data=True, file_name=\"sub001_sess1\",\n                        output_dir=out_dir, overwrite=True)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "syn_results = nighres.registration.embedded_antsreg(\n                        source_image=skullstripping_results1['t1map_masked'],\n                        target_image=skullstripping_results2['t1map_masked'],\n                        run_rigid=True, run_syn=True,\n                        rigid_iterations=1000, coarse_iterations=40,\n                        medium_iterations=0, fine_iterations=0,\n                        cost_function='MutualInformation',\n                        interpolation='NearestNeighbor',\n                        save_data=True, file_name=\"sub001_sess1\",\n                        output_dir=out_dir, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we look at the coregistered image that SyN created\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_img(syn_results['transformed_source'],\n                      annotate=False,  draw_cross=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply deformations to images\n----------------------------\nFinally, we use the computed deformation to transform other associated images\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "deformed = nighres.registration.apply_coordinate_mappings(\n                        image=dataset1['t1map'],\n                        mapping1=syn_results['mapping'],\n                        save_data=True, file_name=\"sub001_sess1_t1map\",\n                        output_dir=out_dir, overwrite=False)\n\ninverse = nighres.registration.apply_coordinate_mappings(\n                        image=dataset2['t1w'],\n                        mapping1=syn_results['inverse'],\n                        save_data=True, file_name=\"sub002_sess1_t1w\",\n                        output_dir=out_dir, overwrite=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we look at the coregistered images from applying the deformation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_img(deformed['result'],\n                      annotate=False,  draw_cross=False)\n    plotting.plot_img(inverse['result'],\n                      annotate=False,  draw_cross=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the example is not run in a jupyter notebook, render the plots:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n-----------\n.. [1] Avants et al (2008). Symmetric diffeomorphic image registration with\n   cross-correlation: evaluating automated labeling of elderly and\n   neurodegenerative brain. DOI: 10.1016/j.media.2007.06.004\n.. [2] Gorgolewski et al (2015). A high resolution 7-Tesla resting-state fMRI\n   test-retest dataset with cognitive and physiological measures.\n   DOI: 10.1038/sdata.2014.54\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}