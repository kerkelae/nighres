{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nMultiatlas Segmentation\n========================\n\nThis example shows how to perform multi-atlas segmentation based on MP2RAGE\ndata by performing the following steps:\n\n1. Downloading three open MP2RAGE datasets using\n    :func:`nighres.data.download_7T_TRT`\n2. Remove the skull and create a brain mask using\n    :func:`nighres.brain.mp2rage_skullstripping`\n3. Atlas-guided tissue classification using MGDMfor first two subjects to\n    be used as an atlas using\n   :func:`nighres.brain.mgdm_segmentation` [1]_\n3. Co-register non-linearly the atlas brains the the third subject using\n    :func:`nighres.registration.embedded_syn` [2]_\n4. Deform segmentation labels using\n    :func:`nighres.registration.apply_deformation`\n5. Turn individual labels into levelset surfaces using\n    :func:`nighres.surface.probability_to_levelset`\n6. Build a final shape average using\n    :func: `nighres.shape.levelset_fusion`\n\nImportant note: this example is both computationally expensive (recomputing\neverything from basic inputs) and practically pointless (a direct MGDM\nsegmentation or a multi-atlas approach with manually defined labels and more\nsubjects would both be meaningful). This example is only meant as illustration.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import and download\n-------------------\nFirst we import ``nighres`` and the ``os`` module to set the output directory\nMake sure to run this file in a  directory you have write access to, or\nchange the ``out_dir`` variable below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nighres\nimport os\nimport nibabel as nb\n\nin_dir = os.path.join(os.getcwd(), 'nighres_examples/data_sets')\nout_dir = os.path.join(os.getcwd(), 'nighres_examples/multiatlas_segmentation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also try to import Nilearn plotting functions. If Nilearn is not\ninstalled, plotting will be skipped.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skip_plots = False\ntry:\n    from nilearn import plotting\nexcept ImportError:\n    skip_plots = True\n    print('Nilearn could not be imported, plotting will be skipped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we download an example MP2RAGE dataset. It is the structural scan of the\nfirst subject, first session of the 7T Test-Retest dataset published by\nGorgolewski et al (2015) [3]_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset1 = nighres.data.download_7T_TRT(in_dir, subject_id='sub001_sess1')\ndataset2 = nighres.data.download_7T_TRT(in_dir, subject_id='sub002_sess1')\ndataset3 = nighres.data.download_7T_TRT(in_dir, subject_id='sub003_sess1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Skull stripping\n----------------\nFirst we perform skull stripping. Only the second inversion image is required\nto calculate the brain mask. But if we input the T1map and T1w image as well,\nthey will be masked for us. We also save the outputs in the ``out_dir``\nspecified above and use a subject ID as the base file_name.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skullstripping_results1 = nighres.brain.mp2rage_skullstripping(\n                                            second_inversion=dataset1['inv2'],\n                                            t1_weighted=dataset1['t1w'],\n                                            t1_map=dataset1['t1map'],\n                                            save_data=True,\n                                            file_name='sub001_sess1',\n                                            output_dir=out_dir)\n\nskullstripping_results2 = nighres.brain.mp2rage_skullstripping(\n                                            second_inversion=dataset2['inv2'],\n                                            t1_weighted=dataset2['t1w'],\n                                            t1_map=dataset2['t1map'],\n                                            save_data=True,\n                                            file_name='sub002_sess1',\n                                            output_dir=out_dir)\n\nskullstripping_results3 = nighres.brain.mp2rage_skullstripping(\n                                            second_inversion=dataset3['inv2'],\n                                            t1_weighted=dataset3['t1w'],\n                                            t1_map=dataset3['t1map'],\n                                            save_data=True,\n                                            file_name='sub003_sess1',\n                                            output_dir=out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip:: in Nighres functions that have several outputs return a\n   dictionary storing the different outputs. You can find the keys in the\n   docstring by typing ``nighres.brain.mp2rage_skullstripping?`` or list\n   them with ``skullstripping_results.keys()``\n\nTo check if the skull stripping worked well we plot the brain mask on top of\nthe original image. You can also open the images stored in ``out_dir`` in\nyour favourite interactive viewer and scroll through the volume.\n\nLike Nilearn, we use Nibabel SpatialImage objects to pass data internally.\nTherefore, we can directly plot the outputs using `Nilearn plotting functions\n<http://nilearn.github.io/plotting/index.html#different-plotting-functions>`_\n.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_roi(skullstripping_results1['brain_mask'], dataset1['t1map'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')\n    plotting.plot_roi(skullstripping_results2['brain_mask'], dataset2['t1w'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')\n    plotting.plot_roi(skullstripping_results3['brain_mask'], dataset3['t1w'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MGDM classification\n---------------------\nNext, we use MGDM to estimate anatomical labels from subjects 1 and 2\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mgdm_results1 = nighres.brain.mgdm_segmentation(\n                        contrast_image1=skullstripping_results1['t1w_masked'],\n                        contrast_type1=\"Mp2rage7T\",\n                        contrast_image2=skullstripping_results1['t1map_masked'],\n                        contrast_type2=\"T1map7T\",\n                        save_data=True, file_name=\"sub001_sess1\",\n                        output_dir=out_dir)\n\nmgdm_results2 = nighres.brain.mgdm_segmentation(\n                        contrast_image1=skullstripping_results2['t1w_masked'],\n                        contrast_type1=\"Mp2rage7T\",\n                        contrast_image2=skullstripping_results2['t1map_masked'],\n                        contrast_type2=\"T1map7T\",\n                        save_data=True, file_name=\"sub002_sess1\",\n                        output_dir=out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we look at the topology-constrained segmentation MGDM created\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_img(mgdm_results1['segmentation'],\n                      vmin=1, vmax=50, cmap='cubehelix',  colorbar=True,\n                      annotate=False,  draw_cross=False)\n    plotting.plot_img(mgdm_results2['segmentation'],\n                      vmin=1, vmax=50, cmap='cubehelix',  colorbar=True,\n                      annotate=False,  draw_cross=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SyN co-registration\n---------------------\nNext, we use the masked data as input for co-registration. The T1 maps are\nused here as they are supposed to be more similar\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "syn_results1 = nighres.registration.embedded_antsreg(\n                        source_image=skullstripping_results1['t1map_masked'],\n                        target_image=skullstripping_results3['t1map_masked'],\n                        run_rigid=True, run_affine=True, run_syn=True,\n                        coarse_iterations=40,\n                        medium_iterations=0, fine_iterations=0,\n                        cost_function='MutualInformation',\n                        interpolation='NearestNeighbor',\n                        save_data=True, file_name=\"sub001_sess1\",\n                        output_dir=out_dir)\n\nsyn_results2 = nighres.registration.embedded_antsreg(\n                        source_image=skullstripping_results2['t1map_masked'],\n                        target_image=skullstripping_results3['t1map_masked'],\n                        run_rigid=True, run_affine=True, run_syn=True,\n                        coarse_iterations=40,\n                        medium_iterations=0, fine_iterations=0,\n                        cost_function='MutualInformation',\n                        interpolation='NearestNeighbor',\n                        save_data=True, file_name=\"sub002_sess1\",\n                        output_dir=out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we look at the coregistered image that SyN created\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_img(syn_results1['transformed_source'],\n                      annotate=False,  draw_cross=False)\n    plotting.plot_img(syn_results2['transformed_source'],\n                      annotate=False,  draw_cross=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply deformations to segmentations\n------------------------------------\nWe use the computed deformation to transform MGDM segmentations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "deformed1 = nighres.registration.apply_coordinate_mappings(\n                        image=mgdm_results1['segmentation'],\n                        mapping1=syn_results1['mapping'],\n                        save_data=True, file_name=\"sub001_sess1_seg\",\n                        output_dir=out_dir)\n\ndeformed2 = nighres.registration.apply_coordinate_mappings(\n                        image=mgdm_results2['segmentation'],\n                        mapping1=syn_results2['mapping'],\n                        save_data=True, file_name=\"sub002_sess1_seg\",\n                        output_dir=out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we look at the segmentations deformed by SyN\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_img(deformed1['result'],\n                      annotate=False,  draw_cross=False)\n    plotting.plot_img(deformed2['result'],\n                      annotate=False,  draw_cross=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform a selected label into levelset representation\n---------------------------------------------------------\nWe use the deformed MGDM segmentations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# label 32 = left caudate\nimg1 = nighres.io.load_volume(deformed1['result'])\nstruct1 = nb.Nifti1Image((img1.get_data()==32).astype(float),\n                            img1.affine, img1.header)\n\nimg2 = nighres.io.load_volume(deformed2['result'])\nstruct2 = nb.Nifti1Image((img2.get_data()==32).astype(float),\n                            img2.affine, img2.header)\n\nlevelset1 = nighres.surface.probability_to_levelset(\n                        probability_image=struct1,\n                        save_data=True, file_name=\"sub001_sess1_struct\",\n                        output_dir=out_dir)\n\nlevelset2 = nighres.surface.probability_to_levelset(\n                        probability_image=struct2,\n                        save_data=True, file_name=\"sub002_sess1_struct\",\n                        output_dir=out_dir)\n\nfinal_seg = nighres.shape.levelset_fusion(levelset_images=[levelset1['result'],\n                        levelset2['result']],\n                        correct_topology=True,\n                        save_data=True, file_name=\"sub003_sess1_struct_seg\",\n                        output_dir=out_dir, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we look at the final segmentation from shape fusion\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    img = nighres.io.load_volume(levelset1['result'])\n    mask = nb.Nifti1Image((img.get_data()<0).astype(bool),\n                                img.affine, img.header)\n    plotting.plot_roi(mask, dataset3['t1map'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')\n\n    img = nighres.io.load_volume(levelset2['result'])\n    mask = nb.Nifti1Image((img.get_data()<0).astype(bool),\n                                img.affine, img.header)\n    plotting.plot_roi(mask, dataset3['t1map'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')\n\n    img = nighres.io.load_volume(final_seg['result'])\n    mask = nb.Nifti1Image((img.get_data()<0).astype(bool),\n                                img.affine, img.header)\n    plotting.plot_roi(mask, dataset3['t1map'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the example is not run in a jupyter notebook, render the plots:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n-----------\n.. [1] Bogovic, Prince and Bazin (2013). A multiple object geometric\n   deformable model for image segmentation. DOI: 10.1016/j.cviu.2012.10.006.A\n.. [2] Avants et al (2008). Symmetric diffeomorphic image registration with\n   cross-correlation: evaluating automated labeling of elderly and\n   neurodegenerative brain. DOI: 10.1016/j.media.2007.06.004\n.. [3] Gorgolewski et al (2015). A high resolution 7-Tesla resting-state fMRI\n   test-retest dataset with cognitive and physiological measures.\n   DOI: 10.1038/sdata.2014.54\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}