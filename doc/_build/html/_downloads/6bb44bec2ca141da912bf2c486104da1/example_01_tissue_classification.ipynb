{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTissue classification from MP2RAGE data\n=======================================\n\nThis example shows how to obtain a tissue classification from MP2RAGE data\nby performing the following steps:\n\n1. Downloading open MP2RAGE dataset using :func:`nighres.data.download_7T_TRT`\n2. Remove the skull and create a brain mask using\n   :func:`nighres.brain.mp2rage_skullstripping`\n3. Atlas-guided tissue classification using MGDM\n   :func:`nighres.brain.mgdm_segmentation` [1]_\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import and download\n-------------------\nFirst we import ``nighres`` and the ``os`` module to set the output directory\nMake sure to run this file in a  directory you have write access to, or\nchange the ``out_dir`` variable below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nighres\nimport os\n\nin_dir = os.path.join(os.getcwd(), 'nighres_examples/data_sets')\nout_dir = os.path.join(os.getcwd(), 'nighres_examples/tissue_classification')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also try to import Nilearn plotting functions. If Nilearn is not\ninstalled, plotting will be skipped.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skip_plots = False\ntry:\n    from nilearn import plotting\nexcept ImportError:\n    skip_plots = True\n    print('Nilearn could not be imported, plotting will be skipped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we download an example MP2RAGE dataset. It is the structural scan of the\nfirst subject, first session of the 7T Test-Retest dataset published by\nGorgolewski et al (2015) [2]_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = nighres.data.download_7T_TRT(in_dir, subject_id='sub001_sess1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Skull stripping\n----------------\nFirst we perform skull stripping. Only the second inversion image is required\nto calculate the brain mask. But if we input the T1map and T1w image as well,\nthey will be masked for us. We also save the outputs in the ``out_dir``\nspecified above and use a subject ID as the base file_name.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skullstripping_results = nighres.brain.mp2rage_skullstripping(\n                                            second_inversion=dataset['inv2'],\n                                            t1_weighted=dataset['t1w'],\n                                            t1_map=dataset['t1map'],\n                                            save_data=True,\n                                            file_name='sub001_sess1',\n                                            output_dir=out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip:: in Nighres functions that have several outputs return a\n   dictionary storing the different outputs. You can find the keys in the\n   docstring by typing ``nighres.brain.mp2rage_skullstripping?`` or list\n   them with ``skullstripping_results.keys()``\n\nTo check if the skull stripping worked well we plot the brain mask on top of\nthe original image. You can also open the images stored in ``out_dir`` in\nyour favourite interactive viewer and scroll through the volume.\n\nLike Nilearn, we use Nibabel SpatialImage objects to pass data internally.\nTherefore, we can directly plot the outputs using `Nilearn plotting functions\n<http://nilearn.github.io/plotting/index.html#different-plotting-functions>`_\n.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_roi(skullstripping_results['brain_mask'], dataset['t1w'],\n                      annotate=False, black_bg=False, draw_cross=False,\n                      cmap='autumn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../_static/tissue_classification1.png)\n\n############################################################################\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MGDM classification\n---------------------\nNext, we use the masked data as input for tissue classification with the MGDM\nalgorithm. MGDM works with a single contrast, but can  be improved with\nadditional contrasts. In this case we use the T1-weigthed  image as well as\nthe quantitative T1map.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mgdm_results = nighres.brain.mgdm_segmentation(\n                        contrast_image1=skullstripping_results['t1w_masked'],\n                        contrast_type1=\"Mp2rage7T\",\n                        contrast_image2=skullstripping_results['t1map_masked'],\n                        contrast_type2=\"T1map7T\",\n                        save_data=True, file_name=\"sub001_sess1\",\n                        output_dir=out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we look at the topology-constrained segmentation MGDM created\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_img(mgdm_results['segmentation'],\n                      vmin=1, vmax=50, cmap='cubehelix',  colorbar=True,\n                      annotate=False,  draw_cross=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../_static/tissue_classification2.png)\n\n############################################################################\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MGDM also creates an image which represents for each voxel the distance to\nits nearest border. It is useful to assess where partial volume effects\nmay occur\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.plot_anat(mgdm_results['distance'], vmin=0, vmax=20,\n                       annotate=False, draw_cross=False, colorbar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../_static/tissue_classification3.png)\n\n############################################################################\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the example is not run in a jupyter notebook, render the plots:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if not skip_plots:\n    plotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n-----------\n.. [1] Bogovic, Prince and Bazin (2013). A multiple object geometric\n   deformable model for image segmentation. DOI: 10.1016/j.cviu.2012.10.006.A\n.. [2] Gorgolewski et al (2015). A high resolution 7-Tesla resting-state fMRI\n   test-retest dataset with cognitive and physiological measures.\n   DOI: 10.1038/sdata.2014.54\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}